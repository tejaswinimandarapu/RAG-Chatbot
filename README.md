# ğŸ“„ Agentic RAG Chatbot with MCP

A multi-format, agent-based Retrieval-Augmented Generation (RAG) chatbot that answers user questions using uploaded documents. Communication between agents follows the Model Context Protocol (MCP).

---

## ğŸš€ Features

- Upload and parse documents in:
  - PDF, PPTX, DOCX, CSV, TXT, MD
- Agentic architecture:
  - `IngestionAgent`, `RetrievalAgent`, `LLMResponseAgent`
- Vector store and semantic search using FAISS
- Embeddings via `SentenceTransformers (MiniLM)`
- LLM integration via OpenAI GPT-3.5 Turbo
- Streamlit-based UI for chatting and document upload
- Messages passed using MCP-like context objects

---

## ğŸ§  Architecture Overview

```plaintext
User Uploads Files + Query
        â†“
[UI (Streamlit)]
        â†“
[IngestionAgent] â€” extracts & embeds text
        â†“
[RetrievalAgent] â€” retrieves relevant chunks
        â†“
[LLMResponseAgent] â€” calls LLM & returns answer
        â†“
[UI] shows final answer + source context
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/agentic-rag-chatbot.git
cd agentic-rag-chatbot
```

### 2. Create a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set your OpenAI API key

Create a `.env` file in the project root:

```
OPENAI_API_KEY=sk-your-openai-key-here
```

Or export it in your shell session:

```bash
export OPENAI_API_KEY="sk-..."
```

### 5. Run the app

```bash
streamlit run app.py
```

---

## ğŸ§ª Usage

1. Open the app in your browser (usually http://localhost:8501)
2. Upload one or more documents
3. Ask a question related to the uploaded content
4. View the generated answer and the source context

---

## ğŸ“¦ Tech Stack

- Python
- Streamlit (UI)
- FAISS (Vector search)
- SentenceTransformers (Embeddings)
- OpenAI GPT-3.5 Turbo (LLM)
- PyPDF2, python-docx, python-pptx, csv (Document parsing)

---

## ğŸ“Œ Folder Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â””â”€â”€ llm_response_agent.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â””â”€â”€ embedding_utils.py
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ faiss_store.py
â”œâ”€â”€ mcp.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§© Future Improvements

- Add multi-turn conversation support
- Introduce `CoordinatorAgent` for orchestration
- Use persistent vector DB (e.g. Chroma)
- Add authentication and file storage

---

## ğŸ“„ License

MIT License
